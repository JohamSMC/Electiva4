{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6-OneR(Regla Unica) - DataSet-Iris.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSUgWhMXd5pebTR1wvIJjJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdmbR5hXsitU",
        "colab_type": "text"
      },
      "source": [
        "# CÃ³digo de :\n",
        "https://www.programmersought.com/article/15123512271/;jsessionid=A57CEB2DDB13EF6F58B64DE905997C15\n",
        "\n",
        "# Weka OneR: \n",
        "https://colab.research.google.com/github/kzafeiroudi/QuestRecommend/blob/master/TrainingOnQuora.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11jn7dlmsurb",
        "colab_type": "text"
      },
      "source": [
        "# Classify Iris plant data with OneR algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tehlwu_PquFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load our dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "#X, y = np.loadtxt(\"X_classification.txt\"), np.loadtxt(\"y_classification.txt\")\n",
        "dataset = load_iris()\n",
        "X = dataset.data\n",
        "y = dataset.target\n",
        "print(dataset.DESCR)\n",
        "n_samples, n_features = X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiFon3l5rBUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute the mean for each attribute\n",
        "attribute_means = X.mean(axis=0)\n",
        "assert attribute_means.shape == (n_features,)\n",
        "X_d = np.array(X >= attribute_means, dtype='int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2ZPSEhsrgN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "def train(X, y_true, feature):\n",
        "    \"\"\"Computes the predictors and error for a given feature using the OneR algorithm\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X: array [n_samples, n_features]   \n",
        "        The two dimensional array that holds the dataset. Each row is a sample, each column\n",
        "        is a feature.\n",
        "\n",
        "    y_true: array [n_samples,]   \n",
        "        The one dimensional array that holds the class values. Corresponds to X, such that\n",
        "        y_true[i] is the class value for sample X[i].\n",
        "\n",
        "    feature: int\n",
        "        An integer corresponding to the index of the variable we wish to test.\n",
        "        0 <= variable < n_features\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    predictors: dictionary of tuples: (value, prediction)\n",
        "        For each item in the array, if the variable has a given value, make the given prediction.\n",
        "\n",
        "    error: float\n",
        "        The ratio of training data that this rule incorrectly predicts.\n",
        "    \"\"\"\n",
        "    # Check that variable is a valid number\n",
        "    n_samples, n_features = X.shape\n",
        "    assert 0 <= feature < n_features\n",
        "    # Get all of the unique values that this variable has\n",
        "    values = set(X[:,feature])\n",
        "    # Stores the predictors array that is returned\n",
        "    predictors = dict()\n",
        "    errors = []\n",
        "    for current_value in values:\n",
        "        most_frequent_class, error = train_feature_value(X, y_true, feature, current_value)\n",
        "        predictors[current_value] = most_frequent_class\n",
        "        errors.append(error)\n",
        "    # Compute the total error of using this feature to classify on\n",
        "    total_error = sum(errors)\n",
        "    return predictors, total_error\n",
        "\n",
        "# Compute what our predictors say each sample is based on its value\n",
        "#y_predicted = np.array([predictors[sample[feature]] for sample in X])\n",
        "\n",
        "\n",
        "def train_feature_value(X, y_true, feature, value):\n",
        "\n",
        "    # The four input parameters are data set, category array, selected feature index value and feature value\n",
        "    # Create a simple dictionary to count how frequency they give certain predictions\n",
        "    class_counts = defaultdict(int)\n",
        "    # Iterate through each sample and count the frequency of each class/value pair\n",
        "    for sample, y in zip(X, y_true):\n",
        "        if sample[feature] == value:\n",
        "            class_counts[y] += 1\n",
        "    # Now get the best one by sorting (highest first) and choosing the first item\n",
        "    sorted_class_counts = sorted(class_counts.items(), key=itemgetter(1), reverse=True)\n",
        "    most_frequent_class = sorted_class_counts[0][0]\n",
        "    # The error is the number of samples that do not classify as the most frequent class\n",
        "    # *and* have the feature value.\n",
        "    n_samples = X.shape[1]\n",
        "    error = sum([class_count for class_value, class_count in class_counts.items()\n",
        "                 if class_value != most_frequent_class])\n",
        "    return most_frequent_class, error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh9cSPn6rpR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fe1f4211-0eb9-456e-e7c4-3e46b4687dc8"
      },
      "source": [
        "# Now, we split into a training and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the random state to the same number to get the same results as in the book\n",
        "random_state = 14\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_d, y, random_state=random_state)\n",
        "print(\"There are {} training samples\".format(y_train.shape))\n",
        "print(\"There are {} testing samples\".format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are (112,) training samples\n",
            "There are (38,) testing samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TvmtTonsBlG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "62898507-2f58-4a2a-8878-5fa14f7645df"
      },
      "source": [
        "# Compute all of the predictors\n",
        "all_predictors = {variable: train(X_train, y_train, variable) for variable in range(X_train.shape[1])}\n",
        "errors = {variable: error for variable, (mapping, error) in all_predictors.items()}\n",
        "# Now choose the best and save that as \"model\"\n",
        "# Sort by error\n",
        "best_variable, best_error = sorted(errors.items(), key=itemgetter(1))[0]\n",
        "print(\"The best model is based on variable {0} and has error {1:.2f}\".format(best_variable, best_error))\n",
        "\n",
        "# Choose the bset model\n",
        "model = {'variable': best_variable,\n",
        "         'predictor': all_predictors[best_variable][0]}\n",
        "\n",
        "def predict(X_test, model):\n",
        "    variable = model['variable']\n",
        "    predictor = model['predictor']\n",
        "    y_predicted = np.array([predictor[int(sample[variable])] for sample in X_test])\n",
        "    return y_predicted\n",
        "\n",
        "y_predicted = predict(X_test, model)\n",
        "\n",
        "\n",
        "# Compute the accuracy by taking the mean of the amounts that y_predicted is equal to y_test\n",
        "accuracy = np.mean(y_predicted == y_test) * 100\n",
        "print(\"The test accuracy is {:.1f}%\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model is based on variable 2 and has error 37.00\n",
            "The test accuracy is 65.8%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}