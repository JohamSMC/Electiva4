{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Taller-DataSet-HorseColic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NnwgdIihj0AEygXrtnMb7VJ7nNQUKsB0",
      "authorship_tag": "ABX9TyOhvz+GNT5jfhXbac+Ee72i"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgkB4JeA-LvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importarcion librerias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYHY0AFa_kwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cargar Datos\n",
        "dataSet = pd.read_csv('/content/drive/My Drive/9° Semestre/Colab Notebooks/DataSets/dataSet-horseColic.txt', sep=' ', na_values=['?'])\n",
        "dataSet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS3dfK6GBafH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Información DataSet\n",
        "dataSet.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-fJsSFIAsxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eliminación de atributos\n",
        "dataSet = dataSet.drop(['surgery'],axis=1)\n",
        "dataSet = dataSet.drop(['Hospital_Number'],axis=1)\n",
        "dataSet = dataSet.drop(['type_of_lesion_1'],axis=1)\n",
        "dataSet = dataSet.drop(['type_of_lesion_2'],axis=1)\n",
        "dataSet = dataSet.drop(['type_of_lesion_3'],axis=1)\n",
        "dataSet = dataSet.drop(['cp_data'],axis=1)\n",
        "dataSet.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDMzJsSPA04U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Valores de la clase\n",
        "dataSet.outcome.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOutfzlEK7CZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Estadisticas descriptivas de dataSet\n",
        "statistics = dataSet.describe()\n",
        "print(statistics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgJUNuvQJ8H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Limpieza de datos perdidos en el atriburo \"outcome\" por el minimo valor\n",
        "dataSet.outcome = dataSet.outcome.fillna(1.0)\n",
        "\n",
        "# Limpieza de los demas datos por la media\n",
        "for column in dataSet:\n",
        "  missing_data = dataSet.loc[:,column].isna()\n",
        "  dataSet.loc[missing_data,column]= statistics.loc['mean',column]\n",
        "\n",
        "dataSet.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5DiMNNXKP5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separa atributos de la clase(\"outcome\")\n",
        "\n",
        "# Cambio tipo de variablde de outcome de int a string\n",
        "dataSet.outcome = dataSet.outcome.astype(str)\n",
        "\n",
        "# Cambia todo los \"outcome\" de valor 3.0 a 2.0 ya que:\n",
        "# 1 = Vivo\n",
        "# 2 = Muerto\n",
        "# 3 = Eeutanasia\n",
        "dataSet.outcome = dataSet.outcome.replace({'3.0':2.0})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrUTcCeFNQB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cargar datos de knime con SMOTE\n",
        "#dataSet = pd.read_csv('/content/drive/My Drive/9° Semestre/Colab Notebooks/DataSets/horse-colic-KnimeSMOTE.csv', sep=',', na_values=['?'])\n",
        "#dataSet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A16wk0NA4WqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataSet.drop(['outcome'],axis=1)\n",
        "y = dataSet['outcome']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_oMc6xPCxr0",
        "colab_type": "text"
      },
      "source": [
        "# **Splitting Data and SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhbLh4h2BvnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 123)\n",
        "\n",
        "# Smote\n",
        "from imblearn.over_sampling import SMOTE \n",
        "sm = SMOTE(random_state = 12345) \n",
        "X_train, y_train= sm.fit_sample(X_train, y_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuNevBs0-CcH",
        "colab_type": "text"
      },
      "source": [
        "# **Árbol de decisión**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx7gsDmhPZtP",
        "colab_type": "text"
      },
      "source": [
        "Links de Ayuda:\n",
        "\n",
        "\n",
        "*   https://scikit-learn.org/stable/modules/tree.html\n",
        "*   https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0jgNy2s-MQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "clf = DecisionTreeClassifier(criterion=\"gini\")\n",
        "# Entrenar Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "# Predecir la respuesta para el conjunto de datos de prueba\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU3rduGp-mpw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "902907a7-3bd7-4b1e-a049-bd3d8ea2d12e"
      },
      "source": [
        "# Resultados\n",
        "\n",
        "#print(\"Numbero de observaciones mal etiquetadas del total de %d observaciones : %d\" %(X_test.shape[0], (y_test != y_pred).sum()))\n",
        "print(\"Numero de datos en test:\",X_test.shape[0])\n",
        "print(\"Numero de aciertos:\",metrics.accuracy_score(y_test,y_pred,normalize=False))\n",
        "print(\"Numero de desaciertos:\",(y_test != y_pred).sum())\n",
        "print(\"Exactitud(Accuracy):\",metrics.accuracy_score(y_test,y_pred))\n",
        "\n",
        "# Matriz de Confución\n",
        "print(\"\\n\\t---Matriz de Confución Árbol de decisión---\")\n",
        "# print(metrics.confusion_matrix(y_test,y_pred))\n",
        "VN,FP,FN,VP = metrics.confusion_matrix(y_test,y_pred).ravel()\n",
        "print(\"VN \\t FP\")\n",
        "print(VN,\" \\t \",FP)\n",
        "print(\"FN \\t VP\")\n",
        "print(FN,\" \\t \",VP)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de datos en test: 270\n",
            "Numero de aciertos: 244\n",
            "Numero de desaciertos: 26\n",
            "Exactitud(Accuracy): 0.9037037037037037\n",
            "\n",
            "\t---Matriz de Confución Árbol de decisión---\n",
            "VN \t FP\n",
            "147  \t  17\n",
            "FN \t VP\n",
            "9  \t  97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlQfyHt76L-g",
        "colab_type": "text"
      },
      "source": [
        "# **Gaussian Naive Bayes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PBqXv8FPtT0",
        "colab_type": "text"
      },
      "source": [
        "Links de ayuda:\n",
        "\n",
        "\n",
        "*   https://scikit-learn.org/stable/modules/naive_bayes.html\n",
        "*   https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgDcKECa6SGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gnb = GaussianNB()\n",
        "y_pred = gnb.fit(X_train, y_train).predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwyhwMOa6bsT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d63cb892-f063-46e1-be1b-63269be9c397"
      },
      "source": [
        "# Resultados\n",
        "\n",
        "#print(\"Numbero de observaciones mal etiquetadas del total de %d observaciones : %d\" %(X_test.shape[0], (y_test != y_pred).sum()))\n",
        "print(\"Numero de datos en test:\",X_test.shape[0])\n",
        "print(\"Numero de aciertos:\",metrics.accuracy_score(y_test,y_pred,normalize=False))\n",
        "print(\"Numero de desaciertos:\",(y_test != y_pred).sum())\n",
        "print(\"Exactitud(Accuracy):\",metrics.accuracy_score(y_test,y_pred))\n",
        "\n",
        "# Matriz de Confución\n",
        "print(\"\\n\\t---Matriz de Confución Naive Bayes---\")\n",
        "# print(metrics.confusion_matrix(y_test,y_pred))\n",
        "VN,FP,FN,VP = metrics.confusion_matrix(y_test,y_pred).ravel()\n",
        "print(\"VN \\t FP\")\n",
        "print(VN,\" \\t \",FP)\n",
        "print(\"FN \\t VP\")\n",
        "print(FN,\" \\t \",VP)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de datos en test: 270\n",
            "Numero de aciertos: 207\n",
            "Numero de desaciertos: 63\n",
            "Exactitud(Accuracy): 0.7666666666666667\n",
            "\n",
            "\t---Matriz de Confución Naive Bayes---\n",
            "VN \t FP\n",
            "129  \t  35\n",
            "FN \t VP\n",
            "28  \t  78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQMMllXAIg-X",
        "colab_type": "text"
      },
      "source": [
        "# ***OneR***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgrZiAS2QGVi",
        "colab_type": "text"
      },
      "source": [
        "Links de ayuda:\n",
        "\n",
        "\n",
        "*   https://www.programmersought.com/article/1245627604/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Ozg22DIo0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_samples, n_features = X.shape\n",
        "attribute_means = X.mean(axis=0)\n",
        "assert attribute_means.shape == (n_features,)\n",
        "X_d = np.array(X >= attribute_means, dtype='int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h56AJxHmI4aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from operator import itemgetter\n",
        "\n",
        "def train(X, y_true, feature):  \n",
        "    # Check that variable is a valid number\n",
        "    n_samples, n_features = X.shape\n",
        "    assert 0 <= feature < n_features\n",
        "    # Get all of the unique values that this variable has\n",
        "    values = set(X[:,feature])\n",
        "    # Stores the predictors array that is returned\n",
        "    predictors = dict()\n",
        "    errors = []\n",
        "    for current_value in values:\n",
        "        most_frequent_class, error = train_feature_value(X, y_true, feature, current_value)\n",
        "        predictors[current_value] = most_frequent_class\n",
        "        errors.append(error)\n",
        "    # Compute the total error of using this feature to classify on\n",
        "    total_error = sum(errors)\n",
        "    return predictors, total_error\n",
        "# Compute what our predictors say each sample is based on its value\n",
        "#y_predicted = np.array([predictors[sample[feature]] for sample in X])\n",
        "def train_feature_value(X, y_true, feature, value):\n",
        "    # The four input parameters are data set, category array, selected feature index value and feature value\n",
        "    # Create a simple dictionary to count how frequency they give certain predictions\n",
        "    class_counts = defaultdict(int)\n",
        "    # Iterate through each sample and count the frequency of each class/value pair\n",
        "    for sample, y in zip(X, y_true):\n",
        "        if sample[feature] == value:\n",
        "            class_counts[y] += 1\n",
        "    # Now get the best one by sorting (highest first) and choosing the first item\n",
        "    sorted_class_counts = sorted(class_counts.items(), key=itemgetter(1), reverse=True)\n",
        "    most_frequent_class = sorted_class_counts[0][0]\n",
        "    # The error is the number of samples that do not classify as the most frequent class\n",
        "    # *and* have the feature value.\n",
        "    n_samples = X.shape[1]\n",
        "    error = sum([class_count for class_value, class_count in class_counts.items()\n",
        "                 if class_value != most_frequent_class])\n",
        "    return most_frequent_class, error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db5GJMukJVpI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b77f1d88-4411-4213-99cc-c73a6c3027f2"
      },
      "source": [
        "# Now, we split into a training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_d, y, test_size = 0.3, random_state = 123)\n",
        "# Smote\n",
        "X_train, y_train= sm.fit_sample(X_train, y_train) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-JbJ1uHI-aS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute all of the predictors\n",
        "all_predictors = {variable: train(X_train, y_train, variable) for variable in range(X_train.shape[1])}\n",
        "errors = {variable: error for variable, (mapping, error) in all_predictors.items()}\n",
        "# Now choose the best and save that as \"model\"\n",
        "# Sort by error\n",
        "best_variable, best_error = sorted(errors.items(), key=itemgetter(1))[0]\n",
        "#print(\"The best model is based on variable {0} and has error {1:.2f}\".format(best_variable, best_error))\n",
        "\n",
        "# Choose the bset model\n",
        "model = {'variable': best_variable,\n",
        "         'predictor': all_predictors[best_variable][0]}\n",
        "\n",
        "def predict(X_test, model):\n",
        "    variable = model['variable']\n",
        "    predictor = model['predictor']\n",
        "    y_pred = np.array([predictor[int(sample[variable])] for sample in X_test])\n",
        "    return y_pred\n",
        "\n",
        "y_pred = predict(X_test, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_lgzsLwKfTs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8519aedd-5491-4ed3-8781-ce743a4c3368"
      },
      "source": [
        "# Resultados\n",
        "\n",
        "#print(\"Numbero de observaciones mal etiquetadas del total de %d observaciones : %d\" %(X_test.shape[0], (y_test != y_pred).sum()))\n",
        "print(\"Numero de datos en test:\",X_test.shape[0])\n",
        "print(\"Numero de aciertos:\",metrics.accuracy_score(y_test,y_pred,normalize=False))\n",
        "print(\"Numero de desaciertos:\",(y_test != y_pred).sum())\n",
        "print(\"Exactitud(Accuracy):\",metrics.accuracy_score(y_test,y_pred))\n",
        "print(\"\\n\\t---Matriz de Confución OneR---\")\n",
        "# print(metrics.confusion_matrix(y_test,y_pred))\n",
        "VN,FP,FN,VP = metrics.confusion_matrix(y_test,y_pred).ravel()\n",
        "print(\"\\nVP \\t FN\")\n",
        "print(VP,\" \\t \",FN)\n",
        "print(\"FP \\t VN\")\n",
        "print(FP,\" \\t \",VN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de datos en test: 270\n",
            "Numero de aciertos: 193\n",
            "Numero de desaciertos: 77\n",
            "Exactitud(Accuracy): 0.7148148148148148\n",
            "\n",
            "\t---Matriz de Confución OneR---\n",
            "\n",
            "VP \t FN\n",
            "56  \t  50\n",
            "FP \t VN\n",
            "27  \t  137\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}